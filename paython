import cv2
import dlib
import pyautogui
from flask import Flask
from flask_socketio import SocketIO, emit
from flask_cors import CORS  # CORS handling
import threading
import logging
import time

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Initialize Flask and SocketIO
app = Flask(_name_)
CORS(app)  # Enable CORS
socketio = SocketIO(app)

# Load face detector and shape predictor
try:
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Ensure this file exists in the same directory
except Exception as e:
    logging.error("Error loading shape predictor. Ensure 'shape_predictor_68_face_landmarks.dat' is present.")
    raise e

# Global variables with thread safety
status_lock = threading.Lock()
eye_tracking_status = "Looking"
fps = 0

# Function to calculate the eye aspect ratio
def eye_aspect_ratio(eye_points):
    A = cv2.norm(eye_points[1] - eye_points[5])
    B = cv2.norm(eye_points[2] - eye_points[4])
    C = cv2.norm(eye_points[0] - eye_points[3])
    return (A + B) / (2.0 * C)

# Eye tracking function
def track_eyes():
    global eye_tracking_status, fps
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        logging.error("Webcam not accessible. Please check your camera.")
        return

    prev_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            logging.error("Failed to read from webcam.")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)
        with status_lock:
            for face in faces:
                landmarks = predictor(gray, face)
                left_eye = landmarks.parts()[36:42]
                right_eye = landmarks.parts()[42:48]

                left_eye_ratio = eye_aspect_ratio(left_eye)
                right_eye_ratio = eye_aspect_ratio(right_eye)

                if left_eye_ratio < 0.2 or right_eye_ratio < 0.2:
                    pyautogui.click()  # Simulate a mouse click on blink
                    eye_tracking_status = "Blink Detected"
                else:
                    eye_tracking_status = "Looking"

        # Calculate FPS
        curr_time = time.time()
        fps = int(1 / (curr_time - prev_time))
        prev_time = curr_time

        # Send data to the WebSocket
        socketio.emit('eye_status', {"eye_tracking_status": eye_tracking_status, "fps": fps})

        cv2.imshow("Eye Tracking", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# Start eye tracking in a separate thread
def start_eye_tracking():
    tracking_thread = threading.Thread(target=track_eyes, daemon=True)
    tracking_thread.start()

# WebSocket event for retrieving eye status
@socketio.on('get_eye_status')
def handle_get_eye_status():
    with status_lock:
        emit('eye_status', {"eye_tracking_status": eye_tracking_status, "fps": fps})

# Start the Flask server with WebSocket
if _name_ == '_main_':  # Corrected this line
    logging.info("Starting Flask server with WebSocket...")
    start_eye_tracking()
    socketio.run(app, debug=True, use_reloader=False)
